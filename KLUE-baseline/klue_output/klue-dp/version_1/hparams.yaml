accumulate_grad_batches: 1
adafactor: false
adam_epsilon: 1.0e-08
arc_space: 512
attention_dropout: null
cache_dir: ''
command: train
config_name: resources/v6_without_dummy_letter_grammatical_symbol_F/eojeol_mecab_fixed_composed_grammatical_symbol_F_wp-64k
data_dir: data/klue_benchmark/klue-dp-v1.1
dataset_size: 10000
decoder_layerdrop: null
decoder_layers: 1
dev_file_name: null
dropout: null
early_stopping_mode: max
encoder_layerdrop: null
encoder_layers: 1
eval_batch_size: 64
fp16: false
gpus:
- 0
gradient_clip_val: 1.0
hidden_size: 768
learning_rate: 5.0e-05
lr_scheduler: linear
max_epochs: 3
max_seq_length: 128
metric_key: micro_f1
model_name_or_path: resources/v6_without_dummy_letter_grammatical_symbol_F/eojeol_mecab_fixed_composed_grammatical_symbol_F_wp-64k
no_pos: false
num_gpus: 1
num_sanity_val_steps: 2
num_workers: 16
output_dir: klue_output/klue-dp/version_1
patience: 10000
pos_dim: 256
seed: 42
task: klue-dp
test_file_name: null
tokenizer_name: resources/v6_without_dummy_letter_grammatical_symbol_F/eojeol_mecab_fixed_composed_grammatical_symbol_F_wp-64k
tpu_cores: null
train_batch_size: 32
train_file_name: null
type_space: 256
verbose_step_count: 100
warmup_ratio: 0.1
warmup_steps: null
weight_decay: 0.0
