{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNK 개수 새기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = pd.read_csv('cb_test.csv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb.columns = ['tokenizer', 'result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eojeol_composed_F</td>\n",
       "      <td>[CLS] 그 하나가 감정이 왜 파괴 ##적인 ##지 명확히 아는 일, 다시 말해,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eojeol_pure_F</td>\n",
       "      <td>[CLS] 그 하나가 감정이 왜 파괴 ##적인 ##지...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>orig_composed_F</td>\n",
       "      <td>[CLS] 그 하나 가 감정 이 왜 파괴 적 인지 명확히 아 는 일 , 다시 말 해...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>orig_pure_F</td>\n",
       "      <td>[CLS] 그 하나 가 감정 이 왜 파괴 적 인지 ᄆ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fixed_composed_F</td>\n",
       "      <td>[CLS] 그 하나 가 감정 이 왜 파괴 적 이 ᆫ지 명확히 아 는 일 , 다시 말...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>fixed_lexical_F</td>\n",
       "      <td>[CLS] 권 시장 이 대권 후보 로 나서 ᆫ다 . [SEP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>fixed_composed_T</td>\n",
       "      <td>[CLS] 권 시장 ⫸이 대권 후보 ⫸로 나서 ⭧ᆫ다 . [SEP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>fixed_pure_T</td>\n",
       "      <td>[CLS] 권 시장 ⫸이 대권 후보 ⫸로 나서 ⭧ᆫ다 ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>fixed_grammatical_T</td>\n",
       "      <td>[CLS] 권 시장 ⫸이 대권 후보 ⫸로 나서 ⭧ᆫ다 . [SEP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>fixed_lexical_T</td>\n",
       "      <td>[CLS] 권 시장 ⫸이 대권 후보 ⫸로 나서 ⭧ᆫ다 . [SEP]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1920 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                tokenizer                                             result\n",
       "0       eojeol_composed_F  [CLS] 그 하나가 감정이 왜 파괴 ##적인 ##지 명확히 아는 일, 다시 말해,...\n",
       "1           eojeol_pure_F  [CLS] 그 하나가 감정이 왜 파괴 ##적인 ##지...\n",
       "2         orig_composed_F  [CLS] 그 하나 가 감정 이 왜 파괴 적 인지 명확히 아 는 일 , 다시 말 해...\n",
       "3             orig_pure_F  [CLS] 그 하나 가 감정 이 왜 파괴 적 인지 ᄆ...\n",
       "4        fixed_composed_F  [CLS] 그 하나 가 감정 이 왜 파괴 적 이 ᆫ지 명확히 아 는 일 , 다시 말...\n",
       "...                   ...                                                ...\n",
       "1915      fixed_lexical_F     [CLS] 권 시장 이 대권 후보 로 나서 ᆫ다 . [SEP]\n",
       "1916     fixed_composed_T              [CLS] 권 시장 ⫸이 대권 후보 ⫸로 나서 ⭧ᆫ다 . [SEP]\n",
       "1917         fixed_pure_T  [CLS] 권 시장 ⫸이 대권 후보 ⫸로 나서 ⭧ᆫ다 ....\n",
       "1918  fixed_grammatical_T           [CLS] 권 시장 ⫸이 대권 후보 ⫸로 나서 ⭧ᆫ다 . [SEP]\n",
       "1919      fixed_lexical_T  [CLS] 권 시장 ⫸이 대권 후보 ⫸로 나서 ⭧ᆫ다 . [SEP]\n",
       "\n",
       "[1920 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb['UNK_count'] = cb['result'].apply(lambda x: x.count('[UNK]')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>result</th>\n",
       "      <th>UNK_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eojeol_composed_F</td>\n",
       "      <td>[CLS] 그 하나가 감정이 왜 파괴 ##적인 ##지 명확히 아는 일, 다시 말해,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eojeol_pure_F</td>\n",
       "      <td>[CLS] 그 하나가 감정이 왜 파괴 ##적인 ##지...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>orig_composed_F</td>\n",
       "      <td>[CLS] 그 하나 가 감정 이 왜 파괴 적 인지 명확히 아 는 일 , 다시 말 해...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>orig_pure_F</td>\n",
       "      <td>[CLS] 그 하나 가 감정 이 왜 파괴 적 인지 ᄆ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fixed_composed_F</td>\n",
       "      <td>[CLS] 그 하나 가 감정 이 왜 파괴 적 이 ᆫ지 명확히 아 는 일 , 다시 말...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>fixed_lexical_F</td>\n",
       "      <td>[CLS] 권 시장 이 대권 후보 로 나서 ᆫ다 . [SEP]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>fixed_composed_T</td>\n",
       "      <td>[CLS] 권 시장 ⫸이 대권 후보 ⫸로 나서 ⭧ᆫ다 . [SEP]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>fixed_pure_T</td>\n",
       "      <td>[CLS] 권 시장 ⫸이 대권 후보 ⫸로 나서 ⭧ᆫ다 ....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>fixed_grammatical_T</td>\n",
       "      <td>[CLS] 권 시장 ⫸이 대권 후보 ⫸로 나서 ⭧ᆫ다 . [SEP]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>fixed_lexical_T</td>\n",
       "      <td>[CLS] 권 시장 ⫸이 대권 후보 ⫸로 나서 ⭧ᆫ다 . [SEP]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1920 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                tokenizer                                             result  \\\n",
       "0       eojeol_composed_F  [CLS] 그 하나가 감정이 왜 파괴 ##적인 ##지 명확히 아는 일, 다시 말해,...   \n",
       "1           eojeol_pure_F  [CLS] 그 하나가 감정이 왜 파괴 ##적인 ##지...   \n",
       "2         orig_composed_F  [CLS] 그 하나 가 감정 이 왜 파괴 적 인지 명확히 아 는 일 , 다시 말 해...   \n",
       "3             orig_pure_F  [CLS] 그 하나 가 감정 이 왜 파괴 적 인지 ᄆ...   \n",
       "4        fixed_composed_F  [CLS] 그 하나 가 감정 이 왜 파괴 적 이 ᆫ지 명확히 아 는 일 , 다시 말...   \n",
       "...                   ...                                                ...   \n",
       "1915      fixed_lexical_F     [CLS] 권 시장 이 대권 후보 로 나서 ᆫ다 . [SEP]   \n",
       "1916     fixed_composed_T              [CLS] 권 시장 ⫸이 대권 후보 ⫸로 나서 ⭧ᆫ다 . [SEP]   \n",
       "1917         fixed_pure_T  [CLS] 권 시장 ⫸이 대권 후보 ⫸로 나서 ⭧ᆫ다 ....   \n",
       "1918  fixed_grammatical_T           [CLS] 권 시장 ⫸이 대권 후보 ⫸로 나서 ⭧ᆫ다 . [SEP]   \n",
       "1919      fixed_lexical_T  [CLS] 권 시장 ⫸이 대권 후보 ⫸로 나서 ⭧ᆫ다 . [SEP]   \n",
       "\n",
       "      UNK_count  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "...         ...  \n",
       "1915          0  \n",
       "1916          0  \n",
       "1917          0  \n",
       "1918          0  \n",
       "1919          0  \n",
       "\n",
       "[1920 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_grouped = cb['UNK_count'].groupby(cb['tokenizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer\n",
       "eojeol_composed_F      160\n",
       "eojeol_pure_F          160\n",
       "fixed_composed_F       160\n",
       "fixed_composed_T       160\n",
       "fixed_grammatical_F    160\n",
       "fixed_grammatical_T    160\n",
       "fixed_lexical_F        160\n",
       "fixed_lexical_T        160\n",
       "fixed_pure_F           160\n",
       "fixed_pure_T           160\n",
       "orig_composed_F        160\n",
       "orig_pure_F            160\n",
       "Name: UNK_count, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_grouped.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer\n",
       "eojeol_composed_F      40\n",
       "eojeol_pure_F          40\n",
       "fixed_composed_F       52\n",
       "fixed_composed_T       52\n",
       "fixed_grammatical_F    52\n",
       "fixed_grammatical_T    52\n",
       "fixed_lexical_F        52\n",
       "fixed_lexical_T        52\n",
       "fixed_pure_F           52\n",
       "fixed_pure_T           52\n",
       "orig_composed_F        52\n",
       "orig_pure_F            52\n",
       "Name: UNK_count, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_grouped.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer\n",
       "eojeol_composed_F      0.250\n",
       "eojeol_pure_F          0.250\n",
       "fixed_composed_F       0.325\n",
       "fixed_composed_T       0.325\n",
       "fixed_grammatical_F    0.325\n",
       "fixed_grammatical_T    0.325\n",
       "fixed_lexical_F        0.325\n",
       "fixed_lexical_T        0.325\n",
       "fixed_pure_F           0.325\n",
       "fixed_pure_T           0.325\n",
       "orig_composed_F        0.325\n",
       "orig_pure_F            0.325\n",
       "Name: UNK_count, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_grouped.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. cola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cola = pd.read_csv('cola_test.csv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eojeol_composed_F</td>\n",
       "      <td>[CLS] 2시 ##까지 그리 갈 ##게. [SEP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eojeol_pure_F</td>\n",
       "      <td>[CLS] 2시 ##까지 그리 갈 ##게. [SEP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>orig_composed_F</td>\n",
       "      <td>[CLS] 2 시 까지 그리 갈게 . [SEP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>orig_pure_F</td>\n",
       "      <td>[CLS] 2 시 까지 그리 갈게 . [SEP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fixed_composed_F</td>\n",
       "      <td>[CLS] 2 시 까지 그리 가 ᆯ게 . [SEP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12715</th>\n",
       "      <td>fixed_lexical_F</td>\n",
       "      <td>[CLS] 흥부 가 놀부 에게 맞 는다 . [SEP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12716</th>\n",
       "      <td>fixed_composed_T</td>\n",
       "      <td>[CLS] 흥부 ⫸가 놀 ##부 ⫸에게 맞 ⭧는다 . [SEP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12717</th>\n",
       "      <td>fixed_pure_T</td>\n",
       "      <td>[CLS] 흥부 ⫸가 놀부 ⫸에게 맞 ⭧는다 . [SEP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12718</th>\n",
       "      <td>fixed_grammatical_T</td>\n",
       "      <td>[CLS] 흥부 ⫸가 놀 ##부 ⫸에게 맞 ⭧는다 . [SEP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12719</th>\n",
       "      <td>fixed_lexical_T</td>\n",
       "      <td>[CLS] 흥부 ⫸가 놀부 ⫸에게 맞 ⭧는다 . [SEP]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12720 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tokenizer                                          result\n",
       "0        eojeol_composed_F                   [CLS] 2시 ##까지 그리 갈 ##게. [SEP]\n",
       "1            eojeol_pure_F           [CLS] 2시 ##까지 그리 갈 ##게. [SEP]\n",
       "2          orig_composed_F                      [CLS] 2 시 까지 그리 갈게 . [SEP]\n",
       "3              orig_pure_F              [CLS] 2 시 까지 그리 갈게 . [SEP]\n",
       "4         fixed_composed_F                    [CLS] 2 시 까지 그리 가 ᆯ게 . [SEP]\n",
       "...                    ...                                             ...\n",
       "12715      fixed_lexical_F           [CLS] 흥부 가 놀부 에게 맞 는다 . [SEP]\n",
       "12716     fixed_composed_T             [CLS] 흥부 ⫸가 놀 ##부 ⫸에게 맞 ⭧는다 . [SEP]\n",
       "12717         fixed_pure_T  [CLS] 흥부 ⫸가 놀부 ⫸에게 맞 ⭧는다 . [SEP]\n",
       "12718  fixed_grammatical_T       [CLS] 흥부 ⫸가 놀 ##부 ⫸에게 맞 ⭧는다 . [SEP]\n",
       "12719      fixed_lexical_T        [CLS] 흥부 ⫸가 놀부 ⫸에게 맞 ⭧는다 . [SEP]\n",
       "\n",
       "[12720 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cola['UNK_count'] = cola['result'].apply(lambda x: x.count('[UNK]')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>result</th>\n",
       "      <th>UNK_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eojeol_composed_F</td>\n",
       "      <td>[CLS] 2시 ##까지 그리 갈 ##게. [SEP]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eojeol_pure_F</td>\n",
       "      <td>[CLS] 2시 ##까지 그리 갈 ##게. [SEP]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>orig_composed_F</td>\n",
       "      <td>[CLS] 2 시 까지 그리 갈게 . [SEP]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>orig_pure_F</td>\n",
       "      <td>[CLS] 2 시 까지 그리 갈게 . [SEP]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fixed_composed_F</td>\n",
       "      <td>[CLS] 2 시 까지 그리 가 ᆯ게 . [SEP]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12715</th>\n",
       "      <td>fixed_lexical_F</td>\n",
       "      <td>[CLS] 흥부 가 놀부 에게 맞 는다 . [SEP]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12716</th>\n",
       "      <td>fixed_composed_T</td>\n",
       "      <td>[CLS] 흥부 ⫸가 놀 ##부 ⫸에게 맞 ⭧는다 . [SEP]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12717</th>\n",
       "      <td>fixed_pure_T</td>\n",
       "      <td>[CLS] 흥부 ⫸가 놀부 ⫸에게 맞 ⭧는다 . [SEP]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12718</th>\n",
       "      <td>fixed_grammatical_T</td>\n",
       "      <td>[CLS] 흥부 ⫸가 놀 ##부 ⫸에게 맞 ⭧는다 . [SEP]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12719</th>\n",
       "      <td>fixed_lexical_T</td>\n",
       "      <td>[CLS] 흥부 ⫸가 놀부 ⫸에게 맞 ⭧는다 . [SEP]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12720 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tokenizer                                          result  \\\n",
       "0        eojeol_composed_F                   [CLS] 2시 ##까지 그리 갈 ##게. [SEP]   \n",
       "1            eojeol_pure_F           [CLS] 2시 ##까지 그리 갈 ##게. [SEP]   \n",
       "2          orig_composed_F                      [CLS] 2 시 까지 그리 갈게 . [SEP]   \n",
       "3              orig_pure_F              [CLS] 2 시 까지 그리 갈게 . [SEP]   \n",
       "4         fixed_composed_F                    [CLS] 2 시 까지 그리 가 ᆯ게 . [SEP]   \n",
       "...                    ...                                             ...   \n",
       "12715      fixed_lexical_F           [CLS] 흥부 가 놀부 에게 맞 는다 . [SEP]   \n",
       "12716     fixed_composed_T             [CLS] 흥부 ⫸가 놀 ##부 ⫸에게 맞 ⭧는다 . [SEP]   \n",
       "12717         fixed_pure_T  [CLS] 흥부 ⫸가 놀부 ⫸에게 맞 ⭧는다 . [SEP]   \n",
       "12718  fixed_grammatical_T       [CLS] 흥부 ⫸가 놀 ##부 ⫸에게 맞 ⭧는다 . [SEP]   \n",
       "12719      fixed_lexical_T        [CLS] 흥부 ⫸가 놀부 ⫸에게 맞 ⭧는다 . [SEP]   \n",
       "\n",
       "       UNK_count  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "...          ...  \n",
       "12715          0  \n",
       "12716          0  \n",
       "12717          0  \n",
       "12718          0  \n",
       "12719          0  \n",
       "\n",
       "[12720 rows x 3 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cola_grouped = cola['UNK_count'].groupby(cola['tokenizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer\n",
       "eojeol_composed_F      1060\n",
       "eojeol_pure_F          1060\n",
       "fixed_composed_F       1060\n",
       "fixed_composed_T       1060\n",
       "fixed_grammatical_F    1060\n",
       "fixed_grammatical_T    1060\n",
       "fixed_lexical_F        1060\n",
       "fixed_lexical_T        1060\n",
       "fixed_pure_F           1060\n",
       "fixed_pure_T           1060\n",
       "orig_composed_F        1060\n",
       "orig_pure_F            1060\n",
       "Name: UNK_count, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cola_grouped.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer\n",
       "eojeol_composed_F      0\n",
       "eojeol_pure_F          0\n",
       "fixed_composed_F       0\n",
       "fixed_composed_T       0\n",
       "fixed_grammatical_F    0\n",
       "fixed_grammatical_T    0\n",
       "fixed_lexical_F        0\n",
       "fixed_lexical_T        0\n",
       "fixed_pure_F           0\n",
       "fixed_pure_T           0\n",
       "orig_composed_F        0\n",
       "orig_pure_F            0\n",
       "Name: UNK_count, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cola_grouped.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer\n",
       "eojeol_composed_F      0.0\n",
       "eojeol_pure_F          0.0\n",
       "fixed_composed_F       0.0\n",
       "fixed_composed_T       0.0\n",
       "fixed_grammatical_F    0.0\n",
       "fixed_grammatical_T    0.0\n",
       "fixed_lexical_F        0.0\n",
       "fixed_lexical_T        0.0\n",
       "fixed_pure_F           0.0\n",
       "fixed_pure_T           0.0\n",
       "orig_composed_F        0.0\n",
       "orig_pure_F            0.0\n",
       "Name: UNK_count, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cola_grouped.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. korsts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "korsts = pd.read_csv('sts_test.csv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "korsts['UNK_count'] = korsts['result'].apply(lambda x: x.count('[UNK]')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "korsts_grouped = korsts['UNK_count'].groupby(korsts['tokenizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer\n",
       "eojeol_composed_F      2758\n",
       "eojeol_pure_F          2758\n",
       "fixed_composed_F       2758\n",
       "fixed_composed_T       2758\n",
       "fixed_grammatical_F    2758\n",
       "fixed_grammatical_T    2758\n",
       "fixed_lexical_F        2758\n",
       "fixed_lexical_T        2758\n",
       "fixed_pure_F           2758\n",
       "fixed_pure_T           2758\n",
       "orig_composed_F        2758\n",
       "orig_pure_F            2758\n",
       "Name: UNK_count, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korsts_grouped.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer\n",
       "eojeol_composed_F      1\n",
       "eojeol_pure_F          0\n",
       "fixed_composed_F       1\n",
       "fixed_composed_T       1\n",
       "fixed_grammatical_F    1\n",
       "fixed_grammatical_T    1\n",
       "fixed_lexical_F        1\n",
       "fixed_lexical_T        1\n",
       "fixed_pure_F           0\n",
       "fixed_pure_T           0\n",
       "orig_composed_F        1\n",
       "orig_pure_F            0\n",
       "Name: UNK_count, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korsts_grouped.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer\n",
       "eojeol_composed_F      0.000363\n",
       "eojeol_pure_F          0.000000\n",
       "fixed_composed_F       0.000363\n",
       "fixed_composed_T       0.000363\n",
       "fixed_grammatical_F    0.000363\n",
       "fixed_grammatical_T    0.000363\n",
       "fixed_lexical_F        0.000363\n",
       "fixed_lexical_T        0.000363\n",
       "fixed_pure_F           0.000000\n",
       "fixed_pure_T           0.000000\n",
       "orig_composed_F        0.000363\n",
       "orig_pure_F            0.000000\n",
       "Name: UNK_count, dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korsts_grouped.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. paws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "paws = pd.read_csv('paws_test.csv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "paws['UNK_count'] = paws['result'].apply(lambda x: x.count('[UNK]')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "paws_grouped = paws['UNK_count'].groupby(paws['tokenizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer\n",
       "eojeol_composed_F      3944\n",
       "eojeol_pure_F          3944\n",
       "fixed_composed_F       3944\n",
       "fixed_composed_T       3944\n",
       "fixed_grammatical_F    3944\n",
       "fixed_grammatical_T    3944\n",
       "fixed_lexical_F        3944\n",
       "fixed_lexical_T        3944\n",
       "fixed_pure_F           3944\n",
       "fixed_pure_T           3944\n",
       "orig_composed_F        3944\n",
       "orig_pure_F            3944\n",
       "Name: UNK_count, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paws_grouped.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer\n",
       "eojeol_composed_F      0\n",
       "eojeol_pure_F          0\n",
       "fixed_composed_F       0\n",
       "fixed_composed_T       0\n",
       "fixed_grammatical_F    0\n",
       "fixed_grammatical_T    0\n",
       "fixed_lexical_F        0\n",
       "fixed_lexical_T        0\n",
       "fixed_pure_F           0\n",
       "fixed_pure_T           0\n",
       "orig_composed_F        0\n",
       "orig_pure_F            0\n",
       "Name: UNK_count, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paws_grouped.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer\n",
       "eojeol_composed_F      0.0\n",
       "eojeol_pure_F          0.0\n",
       "fixed_composed_F       0.0\n",
       "fixed_composed_T       0.0\n",
       "fixed_grammatical_F    0.0\n",
       "fixed_grammatical_T    0.0\n",
       "fixed_lexical_F        0.0\n",
       "fixed_lexical_T        0.0\n",
       "fixed_pure_F           0.0\n",
       "fixed_pure_T           0.0\n",
       "orig_composed_F        0.0\n",
       "orig_pure_F            0.0\n",
       "Name: UNK_count, dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paws_grouped.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kornli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "kornli = pd.read_csv('kornli_test.csv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "kornli['UNK_count'] = kornli['result'].apply(lambda x: x.count('[UNK]')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "kornli_grouped = kornli['UNK_count'].groupby(kornli['tokenizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer\n",
       "eojeol_composed_F      10020\n",
       "eojeol_pure_F          10020\n",
       "fixed_composed_F       10020\n",
       "fixed_composed_T       10020\n",
       "fixed_grammatical_F    10020\n",
       "fixed_grammatical_T    10020\n",
       "fixed_lexical_F        10020\n",
       "fixed_lexical_T        10020\n",
       "fixed_pure_F           10020\n",
       "fixed_pure_T           10020\n",
       "orig_composed_F        10020\n",
       "orig_pure_F            10020\n",
       "Name: UNK_count, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kornli_grouped.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer\n",
       "eojeol_composed_F      12\n",
       "eojeol_pure_F          12\n",
       "fixed_composed_F       12\n",
       "fixed_composed_T       12\n",
       "fixed_grammatical_F    12\n",
       "fixed_grammatical_T    12\n",
       "fixed_lexical_F        12\n",
       "fixed_lexical_T        12\n",
       "fixed_pure_F           12\n",
       "fixed_pure_T           12\n",
       "orig_composed_F        12\n",
       "orig_pure_F            12\n",
       "Name: UNK_count, dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kornli_grouped.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer\n",
       "eojeol_composed_F      0.001198\n",
       "eojeol_pure_F          0.001198\n",
       "fixed_composed_F       0.001198\n",
       "fixed_composed_T       0.001198\n",
       "fixed_grammatical_F    0.001198\n",
       "fixed_grammatical_T    0.001198\n",
       "fixed_lexical_F        0.001198\n",
       "fixed_lexical_T        0.001198\n",
       "fixed_pure_F           0.001198\n",
       "fixed_pure_T           0.001198\n",
       "orig_composed_F        0.001198\n",
       "orig_pure_F            0.001198\n",
       "Name: UNK_count, dtype: float64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kornli_grouped.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nsmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsmc = pd.read_csv('nsmc_test.csv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsmc['UNK_count'] = nsmc['result'].apply(lambda x: x.count('[UNK]')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsmc_grouped = nsmc['UNK_count'].groupby(nsmc['tokenizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer\n",
       "eojeol_composed_F      49997\n",
       "eojeol_pure_F          49997\n",
       "fixed_composed_F       49997\n",
       "fixed_composed_T       49997\n",
       "fixed_grammatical_F    49997\n",
       "fixed_grammatical_T    49997\n",
       "fixed_lexical_F        49997\n",
       "fixed_lexical_T        49997\n",
       "fixed_pure_F           49997\n",
       "fixed_pure_T           49997\n",
       "orig_composed_F        49997\n",
       "orig_pure_F            49997\n",
       "Name: UNK_count, dtype: int64"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsmc_grouped.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer\n",
       "eojeol_composed_F      705\n",
       "eojeol_pure_F          781\n",
       "fixed_composed_F       835\n",
       "fixed_composed_T       835\n",
       "fixed_grammatical_F    835\n",
       "fixed_grammatical_T    835\n",
       "fixed_lexical_F        811\n",
       "fixed_lexical_T        811\n",
       "fixed_pure_F           810\n",
       "fixed_pure_T           810\n",
       "orig_composed_F        835\n",
       "orig_pure_F            810\n",
       "Name: UNK_count, dtype: int64"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsmc_grouped.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer\n",
       "eojeol_composed_F      0.014101\n",
       "eojeol_pure_F          0.015621\n",
       "fixed_composed_F       0.016701\n",
       "fixed_composed_T       0.016701\n",
       "fixed_grammatical_F    0.016701\n",
       "fixed_grammatical_T    0.016701\n",
       "fixed_lexical_F        0.016221\n",
       "fixed_lexical_T        0.016221\n",
       "fixed_pure_F           0.016201\n",
       "fixed_pure_T           0.016201\n",
       "orig_composed_F        0.016701\n",
       "orig_pure_F            0.016201\n",
       "Name: UNK_count, dtype: float64"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsmc_grouped.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nsmc_train (특수문자 제거)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsmc_train = pd.read_csv('nsmc_train.csv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsmc_train['UNK_count'] = nsmc_train['result'].apply(lambda x: x.count('[UNK]')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsmc_train_grouped = nsmc_train['UNK_count'].groupby(nsmc_train['tokenizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer\n",
       "eojeol_composed_F      87382\n",
       "eojeol_pure_F          87382\n",
       "fixed_composed_F       87381\n",
       "fixed_composed_T       87381\n",
       "fixed_grammatical_F    87381\n",
       "fixed_grammatical_T    87381\n",
       "fixed_lexical_F        87381\n",
       "fixed_lexical_T        87381\n",
       "fixed_pure_F           87381\n",
       "fixed_pure_T           87381\n",
       "orig_composed_F        87382\n",
       "orig_pure_F            87381\n",
       "Name: UNK_count, dtype: int64"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsmc_train_grouped.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer\n",
       "eojeol_composed_F       87\n",
       "eojeol_pure_F          209\n",
       "fixed_composed_F        53\n",
       "fixed_composed_T        52\n",
       "fixed_grammatical_F     53\n",
       "fixed_grammatical_T     53\n",
       "fixed_lexical_F          2\n",
       "fixed_lexical_T          2\n",
       "fixed_pure_F             0\n",
       "fixed_pure_T             0\n",
       "orig_composed_F         51\n",
       "orig_pure_F              0\n",
       "Name: UNK_count, dtype: int64"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsmc_train_grouped.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer\n",
       "eojeol_composed_F      0.000996\n",
       "eojeol_pure_F          0.002392\n",
       "fixed_composed_F       0.000607\n",
       "fixed_composed_T       0.000595\n",
       "fixed_grammatical_F    0.000607\n",
       "fixed_grammatical_T    0.000607\n",
       "fixed_lexical_F        0.000023\n",
       "fixed_lexical_T        0.000023\n",
       "fixed_pure_F           0.000000\n",
       "fixed_pure_T           0.000000\n",
       "orig_composed_F        0.000584\n",
       "orig_pure_F            0.000000\n",
       "Name: UNK_count, dtype: float64"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsmc_train_grouped.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = pd.read_csv('pc_test.csv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc['UNK_count'] = pc['result'].apply(lambda x: str(x).count('[UNK]')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_grouped = pc['UNK_count'].groupby(pc['tokenizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer\n",
       "eojeol_composed_F      53877\n",
       "eojeol_pure_F          53877\n",
       "fixed_composed_F       53877\n",
       "fixed_composed_T       53877\n",
       "fixed_grammatical_F    53877\n",
       "fixed_grammatical_T    53877\n",
       "fixed_lexical_F        53877\n",
       "fixed_lexical_T        53877\n",
       "fixed_pure_F           53877\n",
       "fixed_pure_T           53877\n",
       "orig_composed_F        53877\n",
       "orig_pure_F            53877\n",
       "Name: UNK_count, dtype: int64"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc_grouped.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer\n",
       "eojeol_composed_F      10910\n",
       "eojeol_pure_F          10910\n",
       "fixed_composed_F       13209\n",
       "fixed_composed_T       13209\n",
       "fixed_grammatical_F    13209\n",
       "fixed_grammatical_T    13209\n",
       "fixed_lexical_F        13208\n",
       "fixed_lexical_T        13208\n",
       "fixed_pure_F           13208\n",
       "fixed_pure_T           13208\n",
       "orig_composed_F        13209\n",
       "orig_pure_F            13208\n",
       "Name: UNK_count, dtype: int64"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc_grouped.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer\n",
       "eojeol_composed_F      0.202498\n",
       "eojeol_pure_F          0.202498\n",
       "fixed_composed_F       0.245170\n",
       "fixed_composed_T       0.245170\n",
       "fixed_grammatical_F    0.245170\n",
       "fixed_grammatical_T    0.245170\n",
       "fixed_lexical_F        0.245151\n",
       "fixed_lexical_T        0.245151\n",
       "fixed_pure_F           0.245151\n",
       "fixed_pure_T           0.245151\n",
       "orig_composed_F        0.245170\n",
       "orig_pure_F            0.245151\n",
       "Name: UNK_count, dtype: float64"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc_grouped.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = pd.read_csv('dp_test.csv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp['UNK_count'] = dp['result'].apply(lambda x: x.count('[UNK]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_grouped = dp['UNK_count'].groupby(dp['tokenizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer\n",
       "eojeol_composed_F      2001\n",
       "eojeol_pure_F          2001\n",
       "fixed_composed_F       2001\n",
       "fixed_composed_T       2001\n",
       "fixed_grammatical_F    2001\n",
       "fixed_grammatical_T    2001\n",
       "fixed_lexical_F        2001\n",
       "fixed_lexical_T        2001\n",
       "fixed_pure_F           2001\n",
       "fixed_pure_T           2001\n",
       "orig_composed_F        2001\n",
       "orig_pure_F            2001\n",
       "Name: UNK_count, dtype: int64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp_grouped.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer\n",
       "eojeol_composed_F      138\n",
       "eojeol_pure_F          138\n",
       "fixed_composed_F       160\n",
       "fixed_composed_T       160\n",
       "fixed_grammatical_F    160\n",
       "fixed_grammatical_T    160\n",
       "fixed_lexical_F        160\n",
       "fixed_lexical_T        160\n",
       "fixed_pure_F           160\n",
       "fixed_pure_T           160\n",
       "orig_composed_F        160\n",
       "orig_pure_F            160\n",
       "Name: UNK_count, dtype: int64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp_grouped.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer\n",
       "eojeol_composed_F      0.068966\n",
       "eojeol_pure_F          0.068966\n",
       "fixed_composed_F       0.079960\n",
       "fixed_composed_T       0.079960\n",
       "fixed_grammatical_F    0.079960\n",
       "fixed_grammatical_T    0.079960\n",
       "fixed_lexical_F        0.079960\n",
       "fixed_lexical_T        0.079960\n",
       "fixed_pure_F           0.079960\n",
       "fixed_pure_T           0.079960\n",
       "orig_composed_F        0.079960\n",
       "orig_pure_F            0.079960\n",
       "Name: UNK_count, dtype: float64"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp_grouped.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ynat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "ynat = pd.read_csv('ynat_test.csv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "ynat['UNK_count'] = ynat['result'].apply(lambda x: x.count('[UNK]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "ynat_grouped = ynat['UNK_count'].groupby(ynat['tokenizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer\n",
       "eojeol_composed_F      9108\n",
       "eojeol_pure_F          9108\n",
       "fixed_composed_F       9108\n",
       "fixed_composed_T       9108\n",
       "fixed_grammatical_F    9108\n",
       "fixed_grammatical_T    9108\n",
       "fixed_lexical_F        9108\n",
       "fixed_lexical_T        9108\n",
       "fixed_pure_F           9108\n",
       "fixed_pure_T           9108\n",
       "orig_composed_F        9108\n",
       "orig_pure_F            9108\n",
       "Name: UNK_count, dtype: int64"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ynat_grouped.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer\n",
       "eojeol_composed_F      0\n",
       "eojeol_pure_F          0\n",
       "fixed_composed_F       0\n",
       "fixed_composed_T       0\n",
       "fixed_grammatical_F    0\n",
       "fixed_grammatical_T    0\n",
       "fixed_lexical_F        0\n",
       "fixed_lexical_T        0\n",
       "fixed_pure_F           0\n",
       "fixed_pure_T           0\n",
       "orig_composed_F        0\n",
       "orig_pure_F            0\n",
       "Name: UNK_count, dtype: int64"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ynat_grouped.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer\n",
       "eojeol_composed_F      0.0\n",
       "eojeol_pure_F          0.0\n",
       "fixed_composed_F       0.0\n",
       "fixed_composed_T       0.0\n",
       "fixed_grammatical_F    0.0\n",
       "fixed_grammatical_T    0.0\n",
       "fixed_lexical_F        0.0\n",
       "fixed_lexical_T        0.0\n",
       "fixed_pure_F           0.0\n",
       "fixed_pure_T           0.0\n",
       "orig_composed_F        0.0\n",
       "orig_pure_F            0.0\n",
       "Name: UNK_count, dtype: float64"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ynat_grouped.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bongseok/virtualenv/acl/lib/python3.8/site-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../KLUE-baseline/data/klue_benchmark/klue-dp-v1.1/klue-dp-v1.1_dev.tsv',sep='delimiter' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                           ## 토큰 구분자 : \\n\n",
       "1                                         ## 문장 구분자 : \\n\\n\n",
       "2                                               ## 주석 : ##\n",
       "3        ## 칼럼명 : INDEX\\tWORD_FORM\\tLEMMA\\tPOS\\tHEAD\\tD...\n",
       "4        ## klue-dp-v1_dev_00000_wikitree\\t'K팝스타3’ 유희열이...\n",
       "                               ...                        \n",
       "24495                                2\\t완전\\t완전\\tMAG\\t3\\tAP\n",
       "24496                           3\\t가깝고\\t가깝 고\\tVA+EC\\t6\\tVP\n",
       "24497                     4\\t주변에\\t주변 에\\tNNG+JKB\\t6\\tNP_AJT\n",
       "24498                      5\\t마트도\\t마트 도\\tNNP+JX\\t6\\tNP_SBJ\n",
       "24499                   6\\t가까워요.\\t가깝 어요 .\\tVA+EF+SF\\t0\\tVP\n",
       "Name: text, Length: 24500, dtype: object"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df['text'].str.contains('## klue-dp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[df2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>## klue-dp-v1_dev_00000_wikitree\\t'K팝스타3’ 유희열이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>## klue-dp-v1_dev_00001_wikitree\\t재판부는 검찰의 공정한...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>## klue-dp-v1_dev_00002_wikitree\\t아이는 예정보다 일찍 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>## klue-dp-v1_dev_00003_wikitree\\t검증과 여과 없이 배포...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>## klue-dp-v1_dev_00004_wikitree\\t이는 김 전 지검장과 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24459</th>\n",
       "      <td>## klue-dp-v1_dev_01995_airbnb\\t아버지 환갑기념 성인자녀2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24466</th>\n",
       "      <td>## klue-dp-v1_dev_01996_airbnb\\t숙소도 깔끔했고 화장실이나...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24473</th>\n",
       "      <td>## klue-dp-v1_dev_01997_airbnb\\t위치랑 내부시설 자체는 상...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24479</th>\n",
       "      <td>## klue-dp-v1_dev_01998_airbnb\\t다만 체크인 과정에서 호스...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24493</th>\n",
       "      <td>## klue-dp-v1_dev_01999_airbnb\\t지하철에서 완전 가깝고 주...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "4      ## klue-dp-v1_dev_00000_wikitree\\t'K팝스타3’ 유희열이...\n",
       "11     ## klue-dp-v1_dev_00001_wikitree\\t재판부는 검찰의 공정한...\n",
       "27     ## klue-dp-v1_dev_00002_wikitree\\t아이는 예정보다 일찍 ...\n",
       "36     ## klue-dp-v1_dev_00003_wikitree\\t검증과 여과 없이 배포...\n",
       "51     ## klue-dp-v1_dev_00004_wikitree\\t이는 김 전 지검장과 ...\n",
       "...                                                  ...\n",
       "24459  ## klue-dp-v1_dev_01995_airbnb\\t아버지 환갑기념 성인자녀2...\n",
       "24466  ## klue-dp-v1_dev_01996_airbnb\\t숙소도 깔끔했고 화장실이나...\n",
       "24473  ## klue-dp-v1_dev_01997_airbnb\\t위치랑 내부시설 자체는 상...\n",
       "24479  ## klue-dp-v1_dev_01998_airbnb\\t다만 체크인 과정에서 호스...\n",
       "24493  ## klue-dp-v1_dev_01999_airbnb\\t지하철에서 완전 가깝고 주...\n",
       "\n",
       "[2000 rows x 1 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15864/1775849241.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['text'] = df2['text'].apply(lambda x: re.sub('## klue-dp-v1_dev_.*\\t', '', x))\n"
     ]
    }
   ],
   "source": [
    "df2['text'] = df2['text'].apply(lambda x: re.sub('## klue-dp-v1_dev_.*\\t', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'K팝스타3’ 유희열이 홍정희의 탈락에 눈물을 흘렸다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>재판부는 검찰의 공정한 수사에 대한 신뢰가 깨져 버려 최씨와 김씨가 정신적 피해를 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>아이는 예정보다 일찍 태어나 병원에서 치료를 받던 상황이었다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>검증과 여과 없이 배포된 기사들에 오판과 여론은 확산되었고 저는 어느새 치욕스러운 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>이는 김 전 지검장과 함께 근무한 후배 검사들이 사건을 넘겨받게 될 경우 수사의 객...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24459</th>\n",
       "      <td>아버지 환갑기념 성인자녀2명과 부모님이 함께한 여행이었는데요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24466</th>\n",
       "      <td>숙소도 깔끔했고 화장실이나 샤워실도 정말 깨끗합니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24473</th>\n",
       "      <td>위치랑 내부시설 자체는 상당히 만족스럽습니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24479</th>\n",
       "      <td>다만 체크인 과정에서 호스트가 큰 실수를 했던 점과 중심가에서 거리가 조금 있다는게...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24493</th>\n",
       "      <td>지하철에서 완전 가깝고 주변에 마트도 가까워요.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "4                         'K팝스타3’ 유희열이 홍정희의 탈락에 눈물을 흘렸다.\n",
       "11     재판부는 검찰의 공정한 수사에 대한 신뢰가 깨져 버려 최씨와 김씨가 정신적 피해를 ...\n",
       "27                    아이는 예정보다 일찍 태어나 병원에서 치료를 받던 상황이었다.\n",
       "36     검증과 여과 없이 배포된 기사들에 오판과 여론은 확산되었고 저는 어느새 치욕스러운 ...\n",
       "51     이는 김 전 지검장과 함께 근무한 후배 검사들이 사건을 넘겨받게 될 경우 수사의 객...\n",
       "...                                                  ...\n",
       "24459                 아버지 환갑기념 성인자녀2명과 부모님이 함께한 여행이었는데요.\n",
       "24466                      숙소도 깔끔했고 화장실이나 샤워실도 정말 깨끗합니다.\n",
       "24473                          위치랑 내부시설 자체는 상당히 만족스럽습니다.\n",
       "24479  다만 체크인 과정에서 호스트가 큰 실수를 했던 점과 중심가에서 거리가 조금 있다는게...\n",
       "24493                         지하철에서 완전 가깝고 주변에 마트도 가까워요.\n",
       "\n",
       "[2000 rows x 1 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('dp.tsv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ynat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "ynat = pd.read_json('../KLUE-baseline/data/klue_benchmark/ynat-v1.1/ynat-v1.1_dev.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>guid</th>\n",
       "      <th>title</th>\n",
       "      <th>predefined_news_category</th>\n",
       "      <th>label</th>\n",
       "      <th>annotations</th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ynat-v1_dev_00000</td>\n",
       "      <td>5억원 무이자 융자는 되고 7천만원 이사비는 안된다</td>\n",
       "      <td>경제</td>\n",
       "      <td>사회</td>\n",
       "      <td>{'annotators': ['18', '03', '15'], 'annotation...</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LS2D...</td>\n",
       "      <td>2017.09.21. 오후 5:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ynat-v1_dev_00001</td>\n",
       "      <td>왜 수소충전소만 더 멀리 떨어져야 하나 한경연 규제개혁 건의</td>\n",
       "      <td>경제</td>\n",
       "      <td>사회</td>\n",
       "      <td>{'annotators': ['11', '14', '13'], 'annotation...</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LS2D...</td>\n",
       "      <td>2018.11.19. 오전 11:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ynat-v1_dev_00002</td>\n",
       "      <td>항응고제 성분 코로나19에 효과…세포실험서 확인</td>\n",
       "      <td>IT과학</td>\n",
       "      <td>IT과학</td>\n",
       "      <td>{'annotators': ['15', '08', '16'], 'annotation...</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LS2D...</td>\n",
       "      <td>2020.05.14. 오후 2:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ynat-v1_dev_00003</td>\n",
       "      <td>실거래가 가장 비싼 역세권은 신반포역…3.3㎡당 1억 육박</td>\n",
       "      <td>경제</td>\n",
       "      <td>경제</td>\n",
       "      <td>{'annotators': ['14', '13', '12'], 'annotation...</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LS2D...</td>\n",
       "      <td>2020.10.23. 오전 5:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ynat-v1_dev_00004</td>\n",
       "      <td>기자회견 하는 성 소수자 단체</td>\n",
       "      <td>사회</td>\n",
       "      <td>사회</td>\n",
       "      <td>{'annotators': ['03', '18', '02'], 'annotation...</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LS2D...</td>\n",
       "      <td>2020.08.31. 오후 1:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9102</th>\n",
       "      <td>ynat-v1_dev_09102</td>\n",
       "      <td>KB금융 미국 IB 스티펠과 제휴…선진국 시장 공략</td>\n",
       "      <td>경제</td>\n",
       "      <td>경제</td>\n",
       "      <td>{'annotators': ['08', '15', '10'], 'annotation...</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LS2D...</td>\n",
       "      <td>2019.10.21. 오전 10:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9103</th>\n",
       "      <td>ynat-v1_dev_09103</td>\n",
       "      <td>1보 서울시교육청 신종코로나 확산에 개학 연기·휴업 검토</td>\n",
       "      <td>사회</td>\n",
       "      <td>사회</td>\n",
       "      <td>{'annotators': ['09', '15', '10'], 'annotation...</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LS2D...</td>\n",
       "      <td>2020.01.28. 오후 3:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9104</th>\n",
       "      <td>ynat-v1_dev_09104</td>\n",
       "      <td>게시판 키움증권 2020 키움 영웅전 실전투자대회</td>\n",
       "      <td>경제</td>\n",
       "      <td>경제</td>\n",
       "      <td>{'annotators': ['14', '13', '10'], 'annotation...</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LS2D...</td>\n",
       "      <td>2020.09.22. 오전 9:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9105</th>\n",
       "      <td>ynat-v1_dev_09105</td>\n",
       "      <td>답변하는 배기동 국립중앙박물관장</td>\n",
       "      <td>정치</td>\n",
       "      <td>사회</td>\n",
       "      <td>{'annotators': ['18', '07', '02'], 'annotation...</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LS2D...</td>\n",
       "      <td>2018.10.11. 오후 1:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9106</th>\n",
       "      <td>ynat-v1_dev_09106</td>\n",
       "      <td>2020 한국인터넷기자상 시상식 내달 1일 개최…특별상 김성후</td>\n",
       "      <td>사회</td>\n",
       "      <td>사회</td>\n",
       "      <td>{'annotators': ['11', '18', '03'], 'annotation...</td>\n",
       "      <td>https://news.naver.com/main/read.nhn?mode=LS2D...</td>\n",
       "      <td>2020.11.27. 오후 3:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9107 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   guid                               title  \\\n",
       "0     ynat-v1_dev_00000        5억원 무이자 융자는 되고 7천만원 이사비는 안된다   \n",
       "1     ynat-v1_dev_00001   왜 수소충전소만 더 멀리 떨어져야 하나 한경연 규제개혁 건의   \n",
       "2     ynat-v1_dev_00002          항응고제 성분 코로나19에 효과…세포실험서 확인   \n",
       "3     ynat-v1_dev_00003    실거래가 가장 비싼 역세권은 신반포역…3.3㎡당 1억 육박   \n",
       "4     ynat-v1_dev_00004                    기자회견 하는 성 소수자 단체   \n",
       "...                 ...                                 ...   \n",
       "9102  ynat-v1_dev_09102        KB금융 미국 IB 스티펠과 제휴…선진국 시장 공략   \n",
       "9103  ynat-v1_dev_09103     1보 서울시교육청 신종코로나 확산에 개학 연기·휴업 검토   \n",
       "9104  ynat-v1_dev_09104         게시판 키움증권 2020 키움 영웅전 실전투자대회   \n",
       "9105  ynat-v1_dev_09105                   답변하는 배기동 국립중앙박물관장   \n",
       "9106  ynat-v1_dev_09106  2020 한국인터넷기자상 시상식 내달 1일 개최…특별상 김성후   \n",
       "\n",
       "     predefined_news_category label  \\\n",
       "0                          경제    사회   \n",
       "1                          경제    사회   \n",
       "2                        IT과학  IT과학   \n",
       "3                          경제    경제   \n",
       "4                          사회    사회   \n",
       "...                       ...   ...   \n",
       "9102                       경제    경제   \n",
       "9103                       사회    사회   \n",
       "9104                       경제    경제   \n",
       "9105                       정치    사회   \n",
       "9106                       사회    사회   \n",
       "\n",
       "                                            annotations  \\\n",
       "0     {'annotators': ['18', '03', '15'], 'annotation...   \n",
       "1     {'annotators': ['11', '14', '13'], 'annotation...   \n",
       "2     {'annotators': ['15', '08', '16'], 'annotation...   \n",
       "3     {'annotators': ['14', '13', '12'], 'annotation...   \n",
       "4     {'annotators': ['03', '18', '02'], 'annotation...   \n",
       "...                                                 ...   \n",
       "9102  {'annotators': ['08', '15', '10'], 'annotation...   \n",
       "9103  {'annotators': ['09', '15', '10'], 'annotation...   \n",
       "9104  {'annotators': ['14', '13', '10'], 'annotation...   \n",
       "9105  {'annotators': ['18', '07', '02'], 'annotation...   \n",
       "9106  {'annotators': ['11', '18', '03'], 'annotation...   \n",
       "\n",
       "                                                    url                  date  \n",
       "0     https://news.naver.com/main/read.nhn?mode=LS2D...   2017.09.21. 오후 5:09  \n",
       "1     https://news.naver.com/main/read.nhn?mode=LS2D...  2018.11.19. 오전 11:53  \n",
       "2     https://news.naver.com/main/read.nhn?mode=LS2D...   2020.05.14. 오후 2:23  \n",
       "3     https://news.naver.com/main/read.nhn?mode=LS2D...   2020.10.23. 오전 5:31  \n",
       "4     https://news.naver.com/main/read.nhn?mode=LS2D...   2020.08.31. 오후 1:51  \n",
       "...                                                 ...                   ...  \n",
       "9102  https://news.naver.com/main/read.nhn?mode=LS2D...  2019.10.21. 오전 10:49  \n",
       "9103  https://news.naver.com/main/read.nhn?mode=LS2D...   2020.01.28. 오후 3:13  \n",
       "9104  https://news.naver.com/main/read.nhn?mode=LS2D...   2020.09.22. 오전 9:52  \n",
       "9105  https://news.naver.com/main/read.nhn?mode=LS2D...   2018.10.11. 오후 1:11  \n",
       "9106  https://news.naver.com/main/read.nhn?mode=LS2D...   2020.11.27. 오후 3:01  \n",
       "\n",
       "[9107 rows x 7 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ynat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'title'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15864/639947292.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 타이틀만 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mynat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mynat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mynat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ynat.tsv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenv/acl/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenv/acl/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenv/acl/lib/python3.8/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    386\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'title'"
     ]
    }
   ],
   "source": [
    "# 타이틀만 저장\n",
    "ynat = ynat['title']\n",
    "ynat.to_csv('ynat.tsv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get OOV rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [UNK]의 개수 / 문장의 길이 * 100\n",
    "from typing import List\n",
    "\n",
    "def getOOVRatePerSentence(sentence):\n",
    "    # [CLS], [SEP] 제거\n",
    "    sentence = sentence.split()\n",
    "    try:\n",
    "        sentence.remove('[CLS]')\n",
    "        sentence.remove('[SEP]')\n",
    "    except:\n",
    "        pass\n",
    "    OOV_rate = sentence.count('[UNK]') / len(sentence) * 100   \n",
    "    \n",
    "    return OOV_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count of all OOV tokens (OC)\n",
    "def getCountofallOOV(sentence):\n",
    "    sentence = sentence.split()\n",
    "    cnt = 0\n",
    "    cnt += sentence.count('[UNK]')\n",
    "    \n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count of all sentences with OOV tokens, divided by the number of sentences * 100 (OR)\n",
    "def getOOVsentencePerSentences(corpus): #corpus: 토큰화된 문장이 있는 칼럼\n",
    "    cnt = 0\n",
    "    for sentence in corpus:\n",
    "        sentence = sentence.split()\n",
    "#     try:\n",
    "#         sentence.remove('[CLS]')\n",
    "#         sentence.remove('[SEP]')\n",
    "#     except:\n",
    "#         pass\n",
    "        \n",
    "        if '[UNK]' in sentence:\n",
    "            cnt += 1\n",
    "    OR = cnt / len(corpus)\n",
    "    return cnt, len(corpus), OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CLS, SEP] 제거\n",
    "def removeCS(sentence):\n",
    "    try:\n",
    "        sentence.remove('[CLS]', '[SEP]')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [UNK]수 /전체 토큰 수\n",
    "def getOOVdividedbyAllTokens(corpus):\n",
    "    corpus['OC'] = corpus['sentence'].apply(lambda x: getCountofallOOV(x))\n",
    "    corpus['sentence'].apply(lambda x: removeCS(x))\n",
    "    corpus['token_count'] = corpus['sentence'].apply(lambda x: len(x))\n",
    "    OOV_count = corpus['OC'].sum()\n",
    "    token_count = corpus['token_count'].sum()\n",
    "    \n",
    "    return OOV_count, token_count, OOV_count/token_count*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29815786            [CLS] 나 ⫸의 사랑 정말 보이 [UNK] [SEP]\n",
      "36286913    [CLS] 그리고 , SCP - 035 ⫸의 가면 ⫸을 쓰 ⭧면 HP ...\n",
      "36792153    [CLS] * 그 ⫸가 그 학교 ⫸를 보 ⭧ᆫ ##즉 먹 ⭧음직 ⫸도...\n",
      "44638460    [CLS] - 데이 : 힝 . .. 미안 하 ⭧ㅕ . 다음 ⫸부...\n",
      "48720006    [CLS] 주변 ⫸의 백발 ⫸에 희 ⭧ᆫ 눈동자 ⫸를 가ᄌ...\n",
      "Name: sentence, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# OOV 포함 문장 확인\n",
    "print(corpus[corpus['sentence'].str.contains(\"[UNK]\", regex=False, case=True)]['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiprocessing\n",
    "def para_dataframe(df, func, n_cores=4):\n",
    "    df_split = np.array_split(df, n_cores)\n",
    "    pool = Pool(n_cores)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS] 신 세계 ##수의 미궁 2에서 뜬 !! ##아 ##앗 ##!! [SEP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[CLS] 세계 ##수의 미궁 시리즈에 전통 ##으로 등장하는 대사. 2편 ##부터...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[CLS] 세계 ##수의 모험가 ##들이 탐험 ##하는 던전 ##인 수 ##해의 구...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[CLS] 그러나 분배 ##할 수 있는 스킬 포인트는 한정되어 있기 때문에 채집 스...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[CLS] 아 ##앗 ##!! ##이 발생하는 과정을 요약하면 다음과 같다. [SEP]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence\n",
       "0     [CLS] 신 세계 ##수의 미궁 2에서 뜬 !! ##아 ##앗 ##!! [SEP]\n",
       "1  [CLS] 세계 ##수의 미궁 시리즈에 전통 ##으로 등장하는 대사. 2편 ##부터...\n",
       "2  [CLS] 세계 ##수의 모험가 ##들이 탐험 ##하는 던전 ##인 수 ##해의 구...\n",
       "3  [CLS] 그러나 분배 ##할 수 있는 스킬 포인트는 한정되어 있기 때문에 채집 스...\n",
       "4   [CLS] 아 ##앗 ##!! ##이 발생하는 과정을 요약하면 다음과 같다. [SEP]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eojoel_composed\n",
    "import pandas as pd\n",
    "corpus = pd.read_csv('bpe_tokenized/eojeol_mecab_fixed_composed_grammatical_symbol_F_txt', \n",
    "                     sep='\\t', names=['sentence'])\n",
    "corpus.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1905 4452932094 4.2780800600279716e-05\n"
     ]
    }
   ],
   "source": [
    "oov_count, token_count, rate = getOOVdividedbyAllTokens(corpus)\n",
    "print(oov_count, token_count, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "OR = getOOVsentencePerSentences(corpus['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5657537187944736e-05"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['OOV_rate'] = corpus['sentence'].apply(lambda x: getOOVRatePerSentence(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['OC'] = corpus['sentence'].apply(lambda x: getCountofallOOV(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>OOV_rate</th>\n",
       "      <th>OC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS] 신 세계 ##수의 미궁 2에서 뜬 !! ##아 ##앗 ##!! [SEP]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[CLS] 세계 ##수의 미궁 시리즈에 전통 ##으로 등장하는 대사. 2편 ##부터...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[CLS] 세계 ##수의 모험가 ##들이 탐험 ##하는 던전 ##인 수 ##해의 구...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[CLS] 그러나 분배 ##할 수 있는 스킬 포인트는 한정되어 있기 때문에 채집 스...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[CLS] 아 ##앗 ##!! ##이 발생하는 과정을 요약하면 다음과 같다. [SEP]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  OOV_rate  OC\n",
       "0     [CLS] 신 세계 ##수의 미궁 2에서 뜬 !! ##아 ##앗 ##!! [SEP]       0.0   0\n",
       "1  [CLS] 세계 ##수의 미궁 시리즈에 전통 ##으로 등장하는 대사. 2편 ##부터...       0.0   0\n",
       "2  [CLS] 세계 ##수의 모험가 ##들이 탐험 ##하는 던전 ##인 수 ##해의 구...       0.0   0\n",
       "3  [CLS] 그러나 분배 ##할 수 있는 스킬 포인트는 한정되어 있기 때문에 채집 스...       0.0   0\n",
       "4   [CLS] 아 ##앗 ##!! ##이 발생하는 과정을 요약하면 다음과 같다. [SEP]       0.0   0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0003174796808345646 \n",
      " 3.689712566161582e-05 \n",
      " 1905\n"
     ]
    }
   ],
   "source": [
    "print(corpus['OOV_rate'].mean(), '\\n', corpus['OC'].mean(), '\\n', corpus['OC'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OOV 포함 문장 확인\n",
    "print(corpus[corpus['sentence'].str.contains(\"[UNK]\", regex=False, case=True)]['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eojoel_pure\n",
    "import pandas as pd\n",
    "\n",
    "corpus = pd.read_csv('/run/user/1000/gvfs/afp-volume:host=L8221.local,user=bongseok,volume=공유폴더/양봉석/bpe_tokenized/64k/eojeol_mecab_fixed_decomposed_pure_grammatical_symbol_F_txt', \n",
    "                 sep='\\t', names=['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3731 7007251832 5.324483962402567e-05\n"
     ]
    }
   ],
   "source": [
    "oov_count, token_count, rate = getOOVdividedbyAllTokens(corpus)\n",
    "print(oov_count, token_count, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3564, 51630038, 6.902958312755841e-05)\n"
     ]
    }
   ],
   "source": [
    "OR = getOOVsentencePerSentences(corpus['sentence'])\n",
    "print(OR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['OOV_rate'] = corpus['sentence'].apply(lambda x: getOOVRatePerSentence(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['OC'] = corpus['sentence'].apply(lambda x: getCountofallOOV(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>OOV_rate</th>\n",
       "      <th>OC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS] 신 세계수의 미궁 2에서 뜬 !! ##아아 #...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[CLS] 세계수의 미궁 시리즈에 전통 ##으로 드...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[CLS] 세계수의 모험가 ##들이 탐험 ##하는 ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[CLS] 그러나 분배 ##할 수 있는 스킬 포인...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[CLS] 아아 ##ᆺ! ##! ##이 발생하는 과정을 ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  OOV_rate  OC\n",
       "0  [CLS] 신 세계수의 미궁 2에서 뜬 !! ##아아 #...       0.0   0\n",
       "1  [CLS] 세계수의 미궁 시리즈에 전통 ##으로 드...       0.0   0\n",
       "2  [CLS] 세계수의 모험가 ##들이 탐험 ##하는 ...       0.0   0\n",
       "3  [CLS] 그러나 분배 ##할 수 있는 스킬 포인...       0.0   0\n",
       "4  [CLS] 아아 ##ᆺ! ##! ##이 발생하는 과정을 ...       0.0   0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006599384262476776 \n",
      " 7.22641343010439e-05 \n",
      " 3731\n"
     ]
    }
   ],
   "source": [
    "print(corpus['OOV_rate'].mean(), '\\n', corpus['OC'].mean(), '\\n', corpus['OC'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OOV 포함 문장 확인\n",
    "print(corpus[corpus['sentence'].str.contains(\"[UNK]\", regex=False, case=True)]['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orig_composed\n",
    "corpus = pd.read_csv('/run/user/1000/gvfs/afp-volume:host=L8221.local,user=bongseok,volume=공유폴더/양봉석/bpe_tokenized/64k/morpheme_mecab_orig_composed_grammatical_symbol_F_txt', \n",
    "                     sep='\\t', names=['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173 4183740910 4.135055294329878e-06\n"
     ]
    }
   ],
   "source": [
    "oov_count, token_count, rate = getOOVdividedbyAllTokens(corpus)\n",
    "print(oov_count, token_count, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153, 51630038, 2.963391194869932e-06)\n"
     ]
    }
   ],
   "source": [
    "OR = getOOVsentencePerSentences(corpus['sentence'])\n",
    "print(OR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['OOV_rate'] = corpus['sentence'].apply(lambda x: getOOVRatePerSentence(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['OC'] = corpus['sentence'].apply(lambda x: getCountofallOOV(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0647797330785445e-05 \n",
      " 3.3507625928921455e-06 \n",
      " 173\n"
     ]
    }
   ],
   "source": [
    "print(corpus['OOV_rate'].mean(), '\\n', corpus['OC'].mean(), '\\n', corpus['OC'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>OOV_rate</th>\n",
       "      <th>OC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS] 신 세계수 의 미궁 2 에서 뜬 ! ! 아 ##앗 ! ! [SEP]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[CLS] 세계수 의 미궁 시리즈 에 전통 으로 등장 하 는 대사 . 2 편 부터 ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[CLS] 세계수 의 모험가 들 이 탐험 하 는 던전 인 수해 의 구석구석 에 는 ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[CLS] 그러나 분배 할 수 있 는 스킬 포인트 는 한정 되 어 있 기 때문 에 ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[CLS] 아 ##앗 ! ! 이 발생 하 는 과정 을 요약 하 면 다음 과 같 다 ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  OOV_rate  OC\n",
       "0        [CLS] 신 세계수 의 미궁 2 에서 뜬 ! ! 아 ##앗 ! ! [SEP]       0.0   0\n",
       "1  [CLS] 세계수 의 미궁 시리즈 에 전통 으로 등장 하 는 대사 . 2 편 부터 ...       0.0   0\n",
       "2  [CLS] 세계수 의 모험가 들 이 탐험 하 는 던전 인 수해 의 구석구석 에 는 ...       0.0   0\n",
       "3  [CLS] 그러나 분배 할 수 있 는 스킬 포인트 는 한정 되 어 있 기 때문 에 ...       0.0   0\n",
       "4  [CLS] 아 ##앗 ! ! 이 발생 하 는 과정 을 요약 하 면 다음 과 같 다 ...       0.0   0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OOV 포함 문장 확인\n",
    "print(corpus[corpus['sentence'].str.contains(\"[UNK]\", regex=False, case=True)]['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orig_pure\n",
    "corpus = pd.read_csv('/run/user/1000/gvfs/afp-volume:host=L8221.local,user=bongseok,volume=공유폴더/양봉석/bpe_tokenized/64k/morpheme_mecab_orig_decomposed_pure_grammatical_symbol_F_txt', \n",
    "                     sep='\\t', names=['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6798640784 0.0\n"
     ]
    }
   ],
   "source": [
    "oov_count, token_count, rate = getOOVdividedbyAllTokens(corpus)\n",
    "print(oov_count, token_count, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 51630038, 0.0)\n"
     ]
    }
   ],
   "source": [
    "OR = getOOVsentencePerSentences(corpus['sentence'])\n",
    "print(OR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['OOV_rate'] = corpus['sentence'].apply(lambda x: getOOVRatePerSentence(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['OC'] = corpus['sentence'].apply(lambda x: getCountofallOOV(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 \n",
      " 0.0 \n",
      " 0\n"
     ]
    }
   ],
   "source": [
    "print(corpus['OOV_rate'].mean(), '\\n', corpus['OC'].mean(), '\\n', corpus['OC'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>OOV_rate</th>\n",
       "      <th>OC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS] 신 세계수 의 미궁 2 에서 뜬 ! ! 아앗...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[CLS] 세계수 의 미궁 시리즈 에 전통 으로 드...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[CLS] 세계수 의 모험가 들 이 탐험 하 는 ᄃ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[CLS] 그러나 분배 할 수 있 는 스킬 포인ᄐ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[CLS] 아앗 ! ! 이 발생 하 는 과정 을 요ᄋ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  OOV_rate  OC\n",
       "0  [CLS] 신 세계수 의 미궁 2 에서 뜬 ! ! 아앗...       0.0   0\n",
       "1  [CLS] 세계수 의 미궁 시리즈 에 전통 으로 드...       0.0   0\n",
       "2  [CLS] 세계수 의 모험가 들 이 탐험 하 는 ᄃ...       0.0   0\n",
       "3  [CLS] 그러나 분배 할 수 있 는 스킬 포인ᄐ...       0.0   0\n",
       "4  [CLS] 아앗 ! ! 이 발생 하 는 과정 을 요ᄋ...       0.0   0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OOV 포함 문장 확인\n",
    "print(corpus[corpus['sentence'].str.contains(\"[UNK]\", regex=False, case=True)]['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed_composed\n",
    "corpus = pd.read_csv('/run/user/1000/gvfs/afp-volume:host=L8221.local,user=bongseok,volume=공유폴더/양봉석/bpe_tokenized/64k/morpheme_mecab_fixed_composed_grammatical_symbol_F_txt', \n",
    "                     sep='\\t', names=['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176 4360258404 4.036458019060102e-06\n"
     ]
    }
   ],
   "source": [
    "oov_count, token_count, rate = getOOVdividedbyAllTokens(corpus)\n",
    "print(oov_count, token_count, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156, 51630038, 3.0214969045732643e-06)\n"
     ]
    }
   ],
   "source": [
    "OR = getOOVsentencePerSentences(corpus['sentence'])\n",
    "print(OR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['OOV_rate'] = corpus['sentence'].apply(lambda x: getOOVRatePerSentence(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['OC'] = corpus['sentence'].apply(lambda x: getCountofallOOV(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0183302539926738e-05 \n",
      " 3.4088683025954774e-06 \n",
      " 176\n"
     ]
    }
   ],
   "source": [
    "print(corpus['OOV_rate'].mean(), '\\n', corpus['OC'].mean(), '\\n', corpus['OC'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>OOV_rate</th>\n",
       "      <th>OC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS] 신 세계수 의 미궁 2 에서 뜨 ᆫ ! ! 아앗 ! ! [SEP]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[CLS] 세계수 의 미궁 시리즈 에 전통 으로 등장 하 는 대사 . 2 편 부터 ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[CLS] 세계수 의 모험가 들 이 탐험 하 는 던전 이 ᆫ 수해 의 구석구석 에 ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[CLS] 그러나 분배 하 ᆯ 수 있 는 스킬 포인트 는 한정 되 어 있 기 때문 ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[CLS] 아앗 ! ! 이 발생 하 는 과정 을 요약 하 면 다음 과 같 다 . [...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  OOV_rate  OC\n",
       "0         [CLS] 신 세계수 의 미궁 2 에서 뜨 ᆫ ! ! 아앗 ! ! [SEP]       0.0   0\n",
       "1  [CLS] 세계수 의 미궁 시리즈 에 전통 으로 등장 하 는 대사 . 2 편 부터 ...       0.0   0\n",
       "2  [CLS] 세계수 의 모험가 들 이 탐험 하 는 던전 이 ᆫ 수해 의 구석구석 에 ...       0.0   0\n",
       "3  [CLS] 그러나 분배 하 ᆯ 수 있 는 스킬 포인트 는 한정 되 어 있 기 때문 ...       0.0   0\n",
       "4  [CLS] 아앗 ! ! 이 발생 하 는 과정 을 요약 하 면 다음 과 같 다 . [...       0.0   0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed_pure\n",
    "\n",
    "corpus = pd.read_csv('/run/user/1000/gvfs/afp-volume:host=L8221.local,user=bongseok,volume=공유폴더/양봉석/bpe_tokenized/64k/morpheme_mecab_fixed_decomposed_pure_grammatical_symbol_F_txt', \n",
    "                     sep='\\t', names=['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6965034513 0.0\n"
     ]
    }
   ],
   "source": [
    "oov_count, token_count, rate = getOOVdividedbyAllTokens(corpus)\n",
    "print(oov_count, token_count, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "OR = getOOVsentencePerSentences(corpus['sentence'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 51630038, 0.0)\n"
     ]
    }
   ],
   "source": [
    "print(OR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['OOV_rate'] = corpus['sentence'].apply(lambda x: getOOVRatePerSentence(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['OC'] = corpus['sentence'].apply(lambda x: getCountofallOOV(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 \n",
      " 0.0 \n",
      " 0\n"
     ]
    }
   ],
   "source": [
    "print(corpus['OOV_rate'].mean(), '\\n', corpus['OC'].mean(), '\\n', corpus['OC'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>OOV_rate</th>\n",
       "      <th>OC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS] 신 세계수 의 미궁 2 에서 뜨 ᆫ ! ! 아아...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[CLS] 세계수 의 미궁 시리즈 에 전통 으로 드...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[CLS] 세계수 의 모험가 들 이 탐험 하 는 ᄃ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[CLS] 그러나 분배 하 ᆯ 수 있 는 스킬 포인...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[CLS] 아앗 ! ! 이 발생 하 는 과정 을 요ᄋ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  OOV_rate  OC\n",
       "0  [CLS] 신 세계수 의 미궁 2 에서 뜨 ᆫ ! ! 아아...       0.0   0\n",
       "1  [CLS] 세계수 의 미궁 시리즈 에 전통 으로 드...       0.0   0\n",
       "2  [CLS] 세계수 의 모험가 들 이 탐험 하 는 ᄃ...       0.0   0\n",
       "3  [CLS] 그러나 분배 하 ᆯ 수 있 는 스킬 포인...       0.0   0\n",
       "4  [CLS] 아앗 ! ! 이 발생 하 는 과정 을 요ᄋ...       0.0   0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OOV 포함 문장 확인\n",
    "print(corpus[corpus['sentence'].str.contains(\"[UNK]\", regex=False, case=True)]['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fixed_grammatical\n",
    "corpus = pd.read_csv('/run/user/1000/gvfs/afp-volume:host=L8221.local,user=bongseok,volume=공유폴더/양봉석/bpe_tokenized/64k/morpheme_mecab_fixed_decomposed_grammatical_grammatical_symbol_F_txt', \n",
    "                     sep='\\t', names=['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177 5002037657 3.538557926534218e-06\n"
     ]
    }
   ],
   "source": [
    "oov_count, token_count, rate = getOOVdividedbyAllTokens(corpus)\n",
    "print(oov_count, token_count, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "OR = getOOVsentencePerSentences(corpus['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 51630038, 3.0408654744743748e-06)\n"
     ]
    }
   ],
   "source": [
    "print(OR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['OOV_rate'] = corpus['sentence'].apply(lambda x: getOOVRatePerSentence(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['OC'] = corpus['sentence'].apply(lambda x: getCountofallOOV(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0214243654981604e-05 \n",
      " 3.4282368724965883e-06 \n",
      " 177\n"
     ]
    }
   ],
   "source": [
    "print(corpus['OOV_rate'].mean(), '\\n', corpus['OC'].mean(), '\\n', corpus['OC'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>OOV_rate</th>\n",
       "      <th>OC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS] 신 세계수 의 미궁 2 에서 뜨 ᆫ ! ! 아앗 ! ! [SEP]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[CLS] 세계수 의 미궁 시리즈 에 전통 으로 등장 하 는 대사 . 2...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[CLS] 세계수 의 모험가 들 이 탐험 하 는 던전 이 ᆫ 수해 의 구석...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[CLS] 그러나 분배 하 ᆯ 수 있 는 스킬 포인트 는 한정 되 어 있 ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[CLS] 아앗 ! ! 이 발생 하 는 과정 을 요약 하 면 다음 과...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  OOV_rate  OC\n",
       "0      [CLS] 신 세계수 의 미궁 2 에서 뜨 ᆫ ! ! 아앗 ! ! [SEP]       0.0   0\n",
       "1  [CLS] 세계수 의 미궁 시리즈 에 전통 으로 등장 하 는 대사 . 2...       0.0   0\n",
       "2  [CLS] 세계수 의 모험가 들 이 탐험 하 는 던전 이 ᆫ 수해 의 구석...       0.0   0\n",
       "3  [CLS] 그러나 분배 하 ᆯ 수 있 는 스킬 포인트 는 한정 되 어 있 ...       0.0   0\n",
       "4  [CLS] 아앗 ! ! 이 발생 하 는 과정 을 요약 하 면 다음 과...       0.0   0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OOV 포함 문장 확인\n",
    "print(corpus[corpus['sentence'].str.contains(\"[UNK]\", regex=False, case=True)]['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fixed_lexical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_csv('/run/user/1000/gvfs/afp-volume:host=L8221.local,user=bongseok,volume=공유폴더/양봉석/bpe_tokenized/64k/morpheme_mecab_fixed_decomposed_lexical_grammatical_symbol_F_txt', \n",
    "                     sep='\\t', names=['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 6326552279 4.89998321880618e-07\n"
     ]
    }
   ],
   "source": [
    "oov_count, token_count, rate = getOOVdividedbyAllTokens(corpus)\n",
    "print(oov_count, token_count, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "OR = getOOVsentencePerSentences(corpus['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 51630038, 6.004256669344307e-07)\n"
     ]
    }
   ],
   "source": [
    "print(OR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['OOV_rate'] = corpus['sentence'].apply(lambda x: getOOVRatePerSentence(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['OC'] = corpus['sentence'].apply(lambda x: getCountofallOOV(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.976039323005533e-06 \n",
      " 6.004256669344307e-07 \n",
      " 31\n"
     ]
    }
   ],
   "source": [
    "print(corpus['OOV_rate'].mean(), '\\n', corpus['OC'].mean(), '\\n', corpus['OC'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>OOV_rate</th>\n",
       "      <th>OC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS] 신 세계수 의 미궁 2 에서 뜨 ᆫ ! ! 아앗 !...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[CLS] 세계수 의 미궁 시리즈 에 전통 으로 등장...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[CLS] 세계수 의 모험가 들 이 탐험 하 는 던저...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[CLS] 그러나 분배 하 ᆯ 수 있 는 스킬 포인트...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[CLS] 아앗 ! ! 이 발생 하 는 과정 을 요약 하...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  OOV_rate  OC\n",
       "0  [CLS] 신 세계수 의 미궁 2 에서 뜨 ᆫ ! ! 아앗 !...       0.0   0\n",
       "1  [CLS] 세계수 의 미궁 시리즈 에 전통 으로 등장...       0.0   0\n",
       "2  [CLS] 세계수 의 모험가 들 이 탐험 하 는 던저...       0.0   0\n",
       "3  [CLS] 그러나 분배 하 ᆯ 수 있 는 스킬 포인트...       0.0   0\n",
       "4  [CLS] 아앗 ! ! 이 발생 하 는 과정 을 요약 하...       0.0   0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11597712    [CLS] 2018 년 리그 우승 축 승 ##회 에서 \" 2 ...\n",
      "29815786             [CLS] 나 의 사랑 정말 보이 [UNK] [SEP]\n",
      "36286913    [CLS] 그리고 , SCP - 035 의 가면 을 쓰 면 HP 가 ᄁ...\n",
      "36792153    [CLS] * 그 가 그 학교 를 보 ᆫ ##즉 먹 음직 도 하 고...\n",
      "44638460    [CLS] - 데이 : 힝 . .. 미안 하 ㅕ . 다음 부터 ...\n",
      "44692077    [CLS] 아까 다 하 ᆫ다 캐 었 [UNK] 서 러 이제 ᆫ 또 ...\n",
      "44692078    [CLS] 이 문장 을 들 은 사람 들 은 듣 자마자 \" ...\n",
      "44692313       [CLS] 묵 [UNK] 서 러 하 아라 먹 으면서 하 아라 [SEP]\n",
      "45698594    [CLS] # 000000 , # e 5 e 5 e 5 {{{- 2 안산 ᄃ...\n",
      "48720006    [CLS] 주변 의 백발 에 희 ᆫ 눈동자 를 가지 고 ...\n",
      "48823268    [CLS] 짓 - + - 민 = 짓 이민 / 짓 [UNK] [SEP]\n",
      "48823270    [CLS] - 고 - 지 - [UNK] - 으 ##난 - 언 - 엇 수ᄃ...\n",
      "48823271    [CLS] 잇 다 잇 고 잇 지 잇 이민 / 잇 [UNK] ...\n",
      "48823275    [CLS] - 고 - 지 - [UNK] - 으 ##난 - 언 - 엇 수ᄃ...\n",
      "48823276    [CLS] 엇 ##다 엇 고 엇 ##지 엇 이민 / 엇 [UNK...\n",
      "48823278    [CLS] 없 다 없 고 없 지 없이 민 / 없 [UNK] ...\n",
      "48823279    [CLS] 으 ##ᆹ 다 으 ##ᆹ 고 으 ##ᆹ 지 으 ##ᆹ ##이 ᄆ...\n",
      "48823353    [CLS] ' 걸 [UNK] ' 는 ' 것 ᆯ 민 ' 이라고 하 ᆯ ᄉ...\n",
      "48823458    [CLS] 영 [UNK] 알 아지 크 냐 ? < 이렇게 말 하...\n",
      "48823692    [CLS] - 안티 - 한테 , - 에게 이제 우리 덜 안티 ...\n",
      "48823794    [CLS] 낚 으 ##다 [ ] 낚 안 낚 [UNK] 낚 으 곡 ...\n",
      "48823795    [CLS] 좇 다 [ ] 좇 안 좇 [UNK] / 좇 이민 ...\n",
      "48823796           [CLS] 다 [ ] 안 [UNK] / 이민 곡 는 [SEP]\n",
      "48823806    [CLS] ' 이 시민 , 잇 이민 ' 을 ' 잇 [UNK] '...\n",
      "48823812    [CLS] - 고 - 지 - [UNK] - 으 ##난 - 언 - 엇 수ᄃ...\n",
      "48823813    [CLS] 잇 다 잇 고 잇 지 잇 이민 / 잇 [UNK] ...\n",
      "48823814    [CLS] 엇 ##다 엇 고 엇 ##지 엇 이민 / 엇 [UNK...\n",
      "48824905    [CLS] ' 철 ' 자체 는 ' 뻘 ' 이 라는 뜻 을 갖 고...\n",
      "48824912    [CLS] 이 또한 지금 은 명시 하 는 예 가 없 지만 ...\n",
      "49089528    [CLS] - ㄴ 이 고 무신 거 렌 [UNK] 뒈 ##ᆯ 철 ᄋ...\n",
      "50085531    [CLS] 아까 침 에 우리 아가 썰리 는 것 ᆯ 보 고 ...\n",
      "Name: sentence, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# OOV 포함 문장 확인\n",
    "print(corpus[corpus['sentence'].str.contains(\"[UNK]\", regex=False, case=True)]['sentence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed_composed_T\n",
    "corpus = pd.read_csv('/run/user/1000/gvfs/afp-volume:host=L8221.local,user=bongseok,volume=공유폴더/양봉석/bpe_tokenized/64k/morpheme_mecab_fixed_composed_grammatical_symbol_T_txt', \n",
    "                     sep='\\t', names=['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177 4824471271 3.668795813210678e-06\n"
     ]
    }
   ],
   "source": [
    "oov_count, token_count, rate = getOOVdividedbyAllTokens(corpus)\n",
    "print(oov_count, token_count, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 51630038, 3.0408654744743748e-06)\n"
     ]
    }
   ],
   "source": [
    "OR = getOOVsentencePerSentences(corpus['sentence'])\n",
    "    \n",
    "print(OR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['OOV_rate'] = corpus['sentence'].apply(lambda x: getOOVRatePerSentence(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['OC'] = corpus['sentence'].apply(lambda x: getCountofallOOV(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.049983276998578e-05 \n",
      " 3.4282368724965883e-06 \n",
      " 177\n"
     ]
    }
   ],
   "source": [
    "print(corpus['OOV_rate'].mean(), '\\n', corpus['OC'].mean(), '\\n', corpus['OC'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>OOV_rate</th>\n",
       "      <th>OC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS] 신 세계수 ⫸의 미궁 2 ⫸에서 뜨 ⭧ᆫ ! ! 아앗 ! ! [SEP]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[CLS] 세계수 ⫸의 미궁 시리즈 ⫸에 전통 ⫸으로 등장 하 ⭧는 대사 . 2 편...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[CLS] 세계수 ⫸의 모험가 들 ⫸이 탐험 하 ⭧는 던전 이 ⭧ᆫ 수해 ⫸의 구석...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[CLS] 그러나 분배 하 ⭧ᆯ 수 있 ⭧는 스킬 포인트 ⫸는 한정 되 ⭧어 있 ⭧...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[CLS] 아앗 ! ! ⫸이 발생 하 ⭧는 과정 ⫸을 요약 하 ⭧면 다음 ⫸과 같 ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  OOV_rate  OC\n",
       "0      [CLS] 신 세계수 ⫸의 미궁 2 ⫸에서 뜨 ⭧ᆫ ! ! 아앗 ! ! [SEP]       0.0   0\n",
       "1  [CLS] 세계수 ⫸의 미궁 시리즈 ⫸에 전통 ⫸으로 등장 하 ⭧는 대사 . 2 편...       0.0   0\n",
       "2  [CLS] 세계수 ⫸의 모험가 들 ⫸이 탐험 하 ⭧는 던전 이 ⭧ᆫ 수해 ⫸의 구석...       0.0   0\n",
       "3  [CLS] 그러나 분배 하 ⭧ᆯ 수 있 ⭧는 스킬 포인트 ⫸는 한정 되 ⭧어 있 ⭧...       0.0   0\n",
       "4  [CLS] 아앗 ! ! ⫸이 발생 하 ⭧는 과정 ⫸을 요약 하 ⭧면 다음 ⫸과 같 ...       0.0   0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OOV 포함 문장 확인\n",
    "print(corpus[corpus['sentence'].str.contains(\"[UNK]\", regex=False, case=True)]['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed_pure_T\n",
    "corpus = pd.read_csv('/run/user/1000/gvfs/afp-volume:host=L8221.local,user=bongseok,volume=공유폴더/양봉석/bpe_tokenized/64k/morpheme_mecab_fixed_decomposed_pure_grammatical_symbol_T_txt', \n",
    "                     sep='\\t', names=['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 7428399923 0.0\n"
     ]
    }
   ],
   "source": [
    "oov_count, token_count, rate = getOOVdividedbyAllTokens(corpus)\n",
    "print(oov_count, token_count, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 51630038, 0.0)\n"
     ]
    }
   ],
   "source": [
    "OR = getOOVsentencePerSentences(corpus['sentence'])\n",
    "    \n",
    "print(OR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['OOV_rate'] = corpus['sentence'].apply(lambda x: getOOVRatePerSentence(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['OC'] = corpus['sentence'].apply(lambda x: getCountofallOOV(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 \n",
      " 0.0 \n",
      " 0\n"
     ]
    }
   ],
   "source": [
    "print(corpus['OOV_rate'].mean(), '\\n', corpus['OC'].mean(), '\\n', corpus['OC'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>OOV_rate</th>\n",
       "      <th>OC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS] 신 세계수 ⫸의 미궁 2 ⫸에서 뜨 ⭧ᆫ ! ! ᄋ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[CLS] 세계수 ⫸의 미궁 시리즈 ⫸에 전통 ⫸으로...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[CLS] 세계수 ⫸의 모험가 들 ⫸이 탐험 하 ⭧느...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[CLS] 그러나 분배 하 ⭧ᆯ 수 있 ⭧는 스킬 포ᄋ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[CLS] 아앗 ! ! ⫸이 발생 하 ⭧는 과정 ⫸을 ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  OOV_rate  OC\n",
       "0  [CLS] 신 세계수 ⫸의 미궁 2 ⫸에서 뜨 ⭧ᆫ ! ! ᄋ...       0.0   0\n",
       "1  [CLS] 세계수 ⫸의 미궁 시리즈 ⫸에 전통 ⫸으로...       0.0   0\n",
       "2  [CLS] 세계수 ⫸의 모험가 들 ⫸이 탐험 하 ⭧느...       0.0   0\n",
       "3  [CLS] 그러나 분배 하 ⭧ᆯ 수 있 ⭧는 스킬 포ᄋ...       0.0   0\n",
       "4  [CLS] 아앗 ! ! ⫸이 발생 하 ⭧는 과정 ⫸을 ...       0.0   0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OOV 포함 문장 확인\n",
    "print(corpus[corpus['sentence'].str.contains(\"[UNK]\", regex=False, case=True)]['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed_grammatical_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_csv('/run/user/1000/gvfs/afp-volume:host=L8221.local,user=bongseok,volume=공유폴더/양봉석/bpe_tokenized/64k/morpheme_mecab_fixed_decomposed_grammatical_grammatical_symbol_T_txt', \n",
    "                     sep='\\t', names=['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177 5465031625 3.238773572513407e-06\n"
     ]
    }
   ],
   "source": [
    "oov_count, token_count, rate = getOOVdividedbyAllTokens(corpus)\n",
    "print(oov_count, token_count, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 51630038, 3.0408654744743748e-06)\n"
     ]
    }
   ],
   "source": [
    "OR = getOOVsentencePerSentences(corpus['sentence'])\n",
    "    \n",
    "print(OR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['OOV_rate'] = corpus['sentence'].apply(lambda x: getOOVRatePerSentence(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['OC'] = corpus['sentence'].apply(lambda x: getCountofallOOV(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0214150200289482e-05 \n",
      " 3.4282368724965883e-06 \n",
      " 177\n"
     ]
    }
   ],
   "source": [
    "print(corpus['OOV_rate'].mean(), '\\n', corpus['OC'].mean(), '\\n', corpus['OC'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>OOV_rate</th>\n",
       "      <th>OC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS] 신 세계수 ⫸의 미궁 2 ⫸에서 뜨 ⭧ᆫ ! ! 아앗 ! ! [SEP]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[CLS] 세계수 ⫸의 미궁 시리즈 ⫸에 전통 ⫸으로 등장 하 ⭧는 대사...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[CLS] 세계수 ⫸의 모험가 들 ⫸이 탐험 하 ⭧는 던전 이 ⭧ᆫ 수해 ⫸...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[CLS] 그러나 분배 하 ⭧ᆯ 수 있 ⭧는 스킬 포인트 ⫸는 한정 되 ⭧ᄋ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[CLS] 아앗 ! ! ⫸이 발생 하 ⭧는 과정 ⫸을 요약 하 ⭧면 다...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  OOV_rate  OC\n",
       "0   [CLS] 신 세계수 ⫸의 미궁 2 ⫸에서 뜨 ⭧ᆫ ! ! 아앗 ! ! [SEP]       0.0   0\n",
       "1  [CLS] 세계수 ⫸의 미궁 시리즈 ⫸에 전통 ⫸으로 등장 하 ⭧는 대사...       0.0   0\n",
       "2  [CLS] 세계수 ⫸의 모험가 들 ⫸이 탐험 하 ⭧는 던전 이 ⭧ᆫ 수해 ⫸...       0.0   0\n",
       "3  [CLS] 그러나 분배 하 ⭧ᆯ 수 있 ⭧는 스킬 포인트 ⫸는 한정 되 ⭧ᄋ...       0.0   0\n",
       "4  [CLS] 아앗 ! ! ⫸이 발생 하 ⭧는 과정 ⫸을 요약 하 ⭧면 다...       0.0   0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2157462     [CLS] 위 ⫸에서 ⫸ᆫ 킥 킥 이 ⭧라고 하 ⭧지만 사람 ⫸에 따...\n",
      "2166324     [CLS] 바리 ⫸에 이 션 ⫸으로 쌩 쏙 옙 , 싱 깍 옙 , [UNK] ,...\n",
      "2186208     [CLS] 에에 유메 오치 ! ? 안 ⫸이나 야츠 쟌 ! 안 ⫸이나 야츠 스...\n",
      "2283509           [CLS] 닭 ⫸이 언제 ⫸부터 [UNK] 울 ⭧었 ⭧지 [SEP]\n",
      "2378438     [CLS] ㅎ 하 ⭧아 핼 해리 [UNK] ㅅ 시 ##실 시리 맂 ##리 ##즈 ...\n",
      "                                  ...                        \n",
      "50690326    [CLS] 애초 ⫸에 횡단 보도 ⫸를 건너 ⭧ᆯ 때 신호등 ⫸도 안 보 ⭧ᄀ...\n",
      "50812484    [CLS] 오늘 닐 ⭧기 ㅈ 되 ⭧야 [UNK] 이 ⭧랴 ㅕ ##다 ##ㅗ #...\n",
      "50867913           [CLS] 황 ##훈 {{{- 2 을 란 홍 더 [UNK] }}} [SEP]\n",
      "50867938           [CLS] 황 ##훈 {{{- 2 을 란 홍 더 [UNK] }}} [SEP]\n",
      "50918255             [CLS] 쿵 ##쾅 북 치 ⭧고 티키 타카 헤드 [UNK] [SEP]\n",
      "Name: sentence, Length: 157, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# OOV 포함 문장 확인\n",
    "print(corpus[corpus['sentence'].str.contains(\"[UNK]\", regex=False, case=True)]['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed_lexical_T\n",
    "corpus = pd.read_csv('/run/user/1000/gvfs/afp-volume:host=L8221.local,user=bongseok,volume=공유폴더/양봉석/bpe_tokenized/64k/morpheme_mecab_fixed_decomposed_lexical_grammatical_symbol_T_txt', \n",
    "                     sep='\\t', names=['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 6790260896 7.363487318941449e-08\n"
     ]
    }
   ],
   "source": [
    "oov_count, token_count, rate = getOOVdividedbyAllTokens(corpus)\n",
    "print(oov_count, token_count, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 51630038, 9.684284950555333e-08)\n"
     ]
    }
   ],
   "source": [
    "OR = getOOVsentencePerSentences(corpus['sentence'])\n",
    "    \n",
    "print(OR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['OOV_rate'] = corpus['sentence'].apply(lambda x: getOOVRatePerSentence(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['OC'] = corpus['sentence'].apply(lambda x: getCountofallOOV(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corpus['OOV_rate'].mean(), '\\n', corpus['OC'].mean(), '\\n', corpus['OC'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29815786            [CLS] 나 ⫸의 사랑 정말 보이 [UNK] [SEP]\n",
      "36286913    [CLS] 그리고 , SCP - 035 ⫸의 가면 ⫸을 쓰 ⭧면 HP ...\n",
      "36792153    [CLS] * 그 ⫸가 그 학교 ⫸를 보 ⭧ᆫ ##즉 먹 ⭧음직 ⫸도...\n",
      "44638460    [CLS] - 데이 : 힝 . .. 미안 하 ⭧ㅕ . 다음 ⫸부...\n",
      "48720006    [CLS] 주변 ⫸의 백발 ⫸에 희 ⭧ᆫ 눈동자 ⫸를 가ᄌ...\n",
      "Name: sentence, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# OOV 포함 문장 확인\n",
    "print(corpus[corpus['sentence'].str.contains(\"[UNK]\", regex=False, case=True)]['sentence'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acl",
   "language": "python",
   "name": "acl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
